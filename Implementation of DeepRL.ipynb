{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9V-Rn_atzVm8"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w6QojKpmnL7d"
   },
   "source": [
    "### 4.1 Define class DQN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DESXLxAP9fLI",
    "outputId": "872c9e3b-09c3-4778-a46f-f32df9542dd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "############################\n",
    "\n",
    "%tensorflow_version 1.x\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "############################\n",
    "\n",
    "# DQN\n",
    "class DQN:\n",
    "        def __init__(\n",
    "          self,\n",
    "          actions_num,\n",
    "          state_size,\n",
    "          learning_rate = 0.001,\n",
    "          gamma = 0.99,\n",
    "          epsilon_min = 0.05,\n",
    "          epsilon_start = 0.9,\n",
    "          replace_target_iter = 300,\n",
    "          memory_size = 500,\n",
    "          batch_size = 2,\n",
    "          epsilon_increment = None,\n",
    "        ):\n",
    "        self.actions_num = actions_num\n",
    "        self.state_size = state_size\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = gamma\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.replace_target_iter = replace_target_iter\n",
    "        self.memory_size = memory_size\n",
    "        self.batch_size = batch_size\n",
    "        self.epsilon_increment = epsilon_increment\n",
    "        self.epsilon = epsilon_start if epsilon_increment is not None else self.epsilon_min\n",
    "        self.save_model_path = './weights/DQN_model.ckpt'\n",
    "        self.memory_counter = 0\n",
    "\n",
    "        # learned steps counter\n",
    "        self.steps_counter = 0\n",
    "\n",
    "        # initialize memory [s, a, r, s_, done]\n",
    "        self.memory = np.zeros((self.memory_size, state_size * 2 + 3))\n",
    "\n",
    "        # build target_net and q_net\n",
    "        self.build_net()\n",
    "        t_params = tf.get_collection('target_net_params')\n",
    "        q_params = tf.get_collection('q_net_params')\n",
    "        self.replace_target = [tf.assign(t, q) for t, q in zip(t_params, q_params)]\n",
    "\n",
    "        # gpu setting\n",
    "        config = tf.ConfigProto(log_device_placement=False, allow_soft_placement=True)\n",
    "        config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "        self.sess = tf.Session(config=config)\n",
    "\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        def build_net(self):\n",
    "            # build q_net\n",
    "            self.state = tf.placeholder(tf.float32, [None, self.state_size], name='state')\n",
    "            self.q_target = tf.placeholder(tf.float32, [None, self.actions_num], name='Q_target')\n",
    "            with tf.variable_scope('q_net'):\n",
    "                # c_names(collections_names) are the collections to store variables\n",
    "                  c_names, neurons_layer_1, w_initializer, b_initializer = \\\n",
    "                  ['q_net_params', tf.GraphKeys.GLOBAL_VARIABLES], 100, \\\n",
    "                  tf.random_normal_initializer(0., 0.3), tf.constant_initializer(0.1)\n",
    "\n",
    "                # layer 1\n",
    "                with tf.variable_scope('layer_1'):\n",
    "                    w_layer_1 = tf.get_variable('w_layer_1', [self.state_size, neurons_layer_1], initializer=w_initializer, collections=c_names)\n",
    "                    b_layer_1 = tf.get_variable('b_layer_1', [1, neurons_layer_1], initializer=b_initializer, collections=c_names)\n",
    "                    layer_1 = tf.nn.relu(tf.matmul(self.state, w_layer_1) + b_layer_1)\n",
    "\n",
    "                # layer 2\n",
    "                with tf.variable_scope('layer_2'):\n",
    "                    w_layer_2 = tf.get_variable('w_layer_2', [neurons_layer_1, self.actions_num], initializer=w_initializer, collections=c_names)\n",
    "                    b_layer_2 = tf.get_variable('b_layer_2', [1, self.actions_num], initializer=b_initializer, collections=c_names)\n",
    "                    self.q_value = tf.matmul(layer_1, w_layer_2) + b_layer_2\n",
    "\n",
    "            with tf.variable_scope('loss'):\n",
    "                self.loss = tf.reduce_mean(tf.squared_difference(self.q_target, self.q_value))\n",
    "            with tf.variable_scope('train'):\n",
    "                self._train_op = tf.train.AdamOptimizer(self.lr).minimize(self.loss)\n",
    "\n",
    "            # build target_net\n",
    "            self.state_t = tf.placeholder(tf.float32, [None, self.state_size], name='state_t')    # input\n",
    "            with tf.variable_scope('target_net'):\n",
    "                # c_names(collections_names) are the collections to store variables\n",
    "                c_names = ['target_net_params', tf.GraphKeys.GLOBAL_VARIABLES]\n",
    "\n",
    "                # layer 1\n",
    "                with tf.variable_scope('layer_1'):\n",
    "                    w_layer_1 = tf.get_variable('w_layer_1', [self.state_size, neurons_layer_1], initializer=w_initializer, collections=c_names)\n",
    "                    b_layer_1 = tf.get_variable('b_layer_1', [1, neurons_layer_1], initializer=b_initializer, collections=c_names)\n",
    "                    layer_1 = tf.nn.relu(tf.matmul(self.state_t, w_layer_1) + b_layer_1)\n",
    "\n",
    "                # layer 2\n",
    "\n",
    "\n",
    "                # Note that q_next (Q(s’, a’)) is the q value given by the target network while R + Q(s’, a’) is the q_target. \n",
    "                with tf.variable_scope('layer_2'):\n",
    "                    w_layer_2 = tf.get_variable('w_layer_2', [neurons_layer_1, self.actions_num], initializer=w_initializer, collections=c_names)\n",
    "                    b_layer_2 = tf.get_variable('b_layer_2', [1, self.actions_num], initializer=b_initializer, collections=c_names)\n",
    "                    self.q_next = tf.matmul(layer_1, w_layer_2) + b_layer_2\n",
    "\n",
    "      \n",
    "    def store_transition(self, s, a, r, s_, done):\n",
    "        s=s.reshape(-1)\n",
    "        s_=s_.reshape(-1)\n",
    "        transition = np.hstack((s, [a, r], s_, done))\n",
    "\n",
    "        # replace the old memory with new observations\n",
    "        index = self.memory_counter % self.memory_size\n",
    "        self.memory[index, :] = transition\n",
    "\n",
    "        self.memory_counter += 1\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        # to have batch dimension when fed into tf placeholder\n",
    "        observation = observation[np.newaxis, :]\n",
    "        # epsilon-greedy\n",
    "        if np.random.uniform() > self.epsilon:\n",
    "            action_values = self.sess.run(self.q_value, feed_dict={self.state: observation})\n",
    "            action = np.argmax(action_values)\n",
    "        else:\n",
    "            action = np.random.randint(0, self.actions_num)\n",
    "        return action\n",
    "\n",
    "    def learn(self):\n",
    "        # replace target parameters every once a while\n",
    "        if self.steps_counter % self.replace_target_iter == 0:\n",
    "            self.sess.run(self.replace_target)\n",
    "\n",
    "        # sample a batch from the memory\n",
    "        if self.memory_counter > self.memory_size:\n",
    "            sample_index = np.random.choice(self.memory_size, size=self.batch_size)\n",
    "        else:\n",
    "            sample_index = np.random.choice(self.memory_counter, size=self.batch_size)\n",
    "        batch_memory = self.memory[sample_index, :]\n",
    "\n",
    "        q_next, q_value = self.sess.run(\n",
    "          [self.q_next, self.q_value],\n",
    "          feed_dict={\n",
    "            self.state_t: batch_memory[:, -self.state_size-1:-1],  # fixed params # s_\n",
    "            self.state: batch_memory[:, :self.state_size],  # newest params # s\n",
    "          })\n",
    "\n",
    "        # calculate q_target\n",
    "        q_target = q_value.copy()\n",
    "\n",
    "        # only change the action-values of this batch, because we only calculate loss on the batch observations\n",
    "        batch_index = np.arange(self.batch_size, dtype=np.int32)\n",
    "        act_index = batch_memory[:, self.state_size].astype(int)\n",
    "        reward = batch_memory[:, self.state_size + 1]\n",
    "        done = batch_memory[:, -1] \n",
    "        ############################\n",
    "        for batch_idx in batch_index:\n",
    "          # memory -> s,a,r,s_,done\n",
    "            A = act_index[batch_idx]\n",
    "            R = reward[batch_idx]\n",
    "            Done = done[batch_idx]\n",
    "            if Done:\n",
    "                q_target[batch_idx,A] = R\n",
    "            else:\n",
    "                q_target[batch_idx,A] = R + self.gamma*np.max(q_next[batch_idx])\n",
    "\n",
    "\n",
    "        # train q_net\n",
    "        _, self.cost = self.sess.run([self._train_op, self.loss],\n",
    "                        feed_dict= {self.state: batch_memory[:, :self.state_size],\n",
    "                              self.q_target: q_target}\n",
    "                        )\n",
    "        # change epsilon\n",
    "        self.epsilon = self.epsilon - self.epsilon_increment if self.epsilon > self.epsilon_min else self.epsilon_min\n",
    "        self.steps_counter += 1\n",
    "\n",
    "    def store(self):\n",
    "        saver = tf.train.Saver() \n",
    "        saver.save(self.sess, self.save_model_path)\n",
    "  \n",
    "    def restore(self):\n",
    "        saver = tf.train.Saver() \n",
    "        saver.restore(self.sess, self.save_model_path)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CO1aavOnnUHQ"
   },
   "source": [
    "### 4.2 Environment setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "R_Pan2x1XlxB",
    "outputId": "39338ac5-acb5-4860-a512-866e4a507f53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(2)\n",
      "Box(4,)\n",
      "(array([ 0.03467452,  0.15515745, -0.0216516 , -0.34774936]), 1.0, False, {})\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "# cart pole gym environment\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "env._max_episode_steps = 500\n",
    "# state and action space\n",
    "print(env.action_space)\n",
    "print(env.observation_space)\n",
    "# observation\n",
    "env.reset()\n",
    "# state, reward, done, info\n",
    "print(env.step(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0zf1EKuLnaOY"
   },
   "source": [
    "### 4.3 Play and Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UMOz0IC6cJqt"
   },
   "outputs": [],
   "source": [
    "# play the game and train the network\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "episode_length_set = []\n",
    "tf.reset_default_graph()\n",
    "total_time_steps = 100000\n",
    "\n",
    "RL = DQN(actions_num = 2, gamma = 0.99,\n",
    "         state_size = 4, epsilon_start = 1,\n",
    "         learning_rate = 1e-3, epsilon_min = 0.01,\n",
    "         replace_target_iter = 100, memory_size = 5000,\n",
    "         epsilon_increment = 0.00001,)\n",
    "\n",
    "new_state = env.reset()\n",
    "done = False\n",
    "episode_length_counter = 0\n",
    "#print('1',new_state) #for test\n",
    "for step in range(total_time_steps):\n",
    "  # calculate episode length, calculate and take action, observe and store transition into memory.\n",
    "    S = new_state\n",
    "    A = RL.choose_action(S)\n",
    "    S_, R, done, info = env.step(A)\n",
    "    RL.store_transition(S,A,R,S_,done)\n",
    "    if done:\n",
    "        new_state = env.reset()\n",
    "        episode_length_set.append(episode_length_counter+1)\n",
    "        episode_length_counter = 0\n",
    "    else:\n",
    "        new_state = S_ \n",
    "  \n",
    "    if step > 200:\n",
    "        RL.learn()\n",
    "   # break # for test\n",
    "    episode_length_counter += 1\n",
    "    if episode_length_counter == 500:\n",
    "        RL.store()\n",
    "RL.store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "LCxAuNQegi2Q",
    "outputId": "7778f441-b45e-4086-af82-6389e31c11e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5d0fe52fd0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD4CAYAAAAEhuazAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAwOtWvnsmaodAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(episode_length_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aeXGUqqznhrw"
   },
   "source": [
    "### 4.4 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "KF1UKCM3rp4m",
    "outputId": "068d58e7-1de5-4977-e1cc-09dcbcb47044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./weights/DQN_model.ckpt\n",
      "During the trail  1  , the agent played  386 unit time\n",
      "During the trail  2  , the agent played  377 unit time\n",
      "During the trail  3  , the agent played  436 unit time\n",
      "During the trail  4  , the agent played  397 unit time\n",
      "During the trail  5  , the agent played  380 unit time\n",
      "During the trail  6  , the agent played  436 unit time\n",
      "During the trail  7  , the agent played  405 unit time\n",
      "During the trail  8  , the agent played  403 unit time\n",
      "During the trail  9  , the agent played  341 unit time\n",
      "During the trail  10  , the agent played  371 unit time\n",
      "During the trail  11  , the agent played  434 unit time\n",
      "During the trail  12  , the agent played  363 unit time\n",
      "During the trail  13  , the agent played  324 unit time\n",
      "During the trail  14  , the agent played  435 unit time\n",
      "During the trail  15  , the agent played  357 unit time\n",
      "During the trail  16  , the agent played  411 unit time\n",
      "During the trail  17  , the agent played  392 unit time\n",
      "During the trail  18  , the agent played  370 unit time\n",
      "During the trail  19  , the agent played  426 unit time\n",
      "During the trail  20  , the agent played  443 unit time\n",
      "During the trail  21  , the agent played  354 unit time\n",
      "During the trail  22  , the agent played  397 unit time\n",
      "During the trail  23  , the agent played  384 unit time\n",
      "During the trail  24  , the agent played  396 unit time\n",
      "During the trail  25  , the agent played  411 unit time\n",
      "During the trail  26  , the agent played  387 unit time\n",
      "During the trail  27  , the agent played  399 unit time\n",
      "During the trail  28  , the agent played  384 unit time\n",
      "During the trail  29  , the agent played  425 unit time\n",
      "During the trail  30  , the agent played  402 unit time\n",
      "During the trail  31  , the agent played  348 unit time\n",
      "During the trail  32  , the agent played  415 unit time\n",
      "During the trail  33  , the agent played  411 unit time\n",
      "During the trail  34  , the agent played  332 unit time\n",
      "During the trail  35  , the agent played  390 unit time\n",
      "During the trail  36  , the agent played  393 unit time\n",
      "During the trail  37  , the agent played  459 unit time\n",
      "During the trail  38  , the agent played  357 unit time\n",
      "During the trail  39  , the agent played  401 unit time\n",
      "During the trail  40  , the agent played  425 unit time\n",
      "During the trail  41  , the agent played  361 unit time\n",
      "During the trail  42  , the agent played  461 unit time\n",
      "During the trail  43  , the agent played  368 unit time\n",
      "During the trail  44  , the agent played  333 unit time\n",
      "During the trail  45  , the agent played  399 unit time\n",
      "During the trail  46  , the agent played  448 unit time\n",
      "During the trail  47  , the agent played  327 unit time\n",
      "During the trail  48  , the agent played  331 unit time\n",
      "During the trail  49  , the agent played  401 unit time\n",
      "During the trail  50  , the agent played  331 unit time\n",
      "During the trail  51  , the agent played  429 unit time\n",
      "During the trail  52  , the agent played  445 unit time\n",
      "During the trail  53  , the agent played  363 unit time\n",
      "During the trail  54  , the agent played  378 unit time\n",
      "During the trail  55  , the agent played  430 unit time\n",
      "During the trail  56  , the agent played  486 unit time\n",
      "During the trail  57  , the agent played  374 unit time\n",
      "During the trail  58  , the agent played  335 unit time\n",
      "During the trail  59  , the agent played  358 unit time\n",
      "During the trail  60  , the agent played  396 unit time\n",
      "During the trail  61  , the agent played  358 unit time\n",
      "During the trail  62  , the agent played  397 unit time\n",
      "During the trail  63  , the agent played  330 unit time\n",
      "During the trail  64  , the agent played  386 unit time\n",
      "During the trail  65  , the agent played  370 unit time\n",
      "During the trail  66  , the agent played  442 unit time\n",
      "During the trail  67  , the agent played  365 unit time\n",
      "During the trail  68  , the agent played  353 unit time\n",
      "During the trail  69  , the agent played  409 unit time\n",
      "During the trail  70  , the agent played  344 unit time\n",
      "During the trail  71  , the agent played  426 unit time\n",
      "During the trail  72  , the agent played  344 unit time\n",
      "During the trail  73  , the agent played  352 unit time\n",
      "During the trail  74  , the agent played  332 unit time\n",
      "During the trail  75  , the agent played  349 unit time\n",
      "During the trail  76  , the agent played  394 unit time\n",
      "During the trail  77  , the agent played  357 unit time\n",
      "During the trail  78  , the agent played  397 unit time\n",
      "During the trail  79  , the agent played  398 unit time\n",
      "During the trail  80  , the agent played  333 unit time\n",
      "During the trail  81  , the agent played  358 unit time\n",
      "During the trail  82  , the agent played  418 unit time\n",
      "During the trail  83  , the agent played  382 unit time\n",
      "During the trail  84  , the agent played  385 unit time\n",
      "During the trail  85  , the agent played  361 unit time\n",
      "During the trail  86  , the agent played  352 unit time\n",
      "During the trail  87  , the agent played  470 unit time\n",
      "During the trail  88  , the agent played  377 unit time\n",
      "During the trail  89  , the agent played  335 unit time\n",
      "During the trail  90  , the agent played  385 unit time\n",
      "During the trail  91  , the agent played  373 unit time\n",
      "During the trail  92  , the agent played  428 unit time\n",
      "During the trail  93  , the agent played  388 unit time\n",
      "During the trail  94  , the agent played  381 unit time\n",
      "During the trail  95  , the agent played  348 unit time\n",
      "During the trail  96  , the agent played  369 unit time\n",
      "During the trail  97  , the agent played  351 unit time\n",
      "During the trail  98  , the agent played  346 unit time\n",
      "During the trail  99  , the agent played  348 unit time\n",
      "During the trail  100  , the agent played  418 unit time\n"
     ]
    }
   ],
   "source": [
    "# test our network\n",
    "tf.reset_default_graph()\n",
    "RL = DQN(actions_num = 2, gamma = 1,\n",
    "         state_size = 4, epsilon_start = 1,\n",
    "         learning_rate = 1e-3, epsilon_min = 0,\n",
    "         replace_target_iter = 100, memory_size = 5000,\n",
    "         epsilon_increment = None,)\n",
    "# load saved parameters\n",
    "RL.restore()\n",
    "# run 100 trails and print how long can the agent hold the cart pole for each trail\n",
    "for i in range(100):\n",
    "    new_state = env.reset()\n",
    "    done = False\n",
    "    episode_length_counter = 0\n",
    "    while (not done):\n",
    "        S = new_state\n",
    "        A = RL.choose_action(S)\n",
    "        S_, R, done, info = env.step(A)\n",
    "    #RL.store_transition(S,A,R,S_,done)\n",
    "        episode_length_counter += 1\n",
    "        new_state = S_ \n",
    "    print('During the trail ', i+1, ' , the agent played ', episode_length_counter, 'unit time')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QYGTLZOjPOLJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of ELEN_6885_HW4_Part_4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
